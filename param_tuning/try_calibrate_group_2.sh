export PYTHONPATH=/home/zhangyanqi/Projects/eLLM:$PYTHONPATH
# ******** qwq-32b minerva_math 88-88
# quant
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 8 --kbits-low 8 --vbits-low 8 --kv-prune-thresh 0.0 --kv-quant-thresh 0.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 0.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 1.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 1.5 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 2.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 2.5 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 3.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 4.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.0 --kv-quant-thresh 5.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
# prune
python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.02 --kv-quant-thresh 3.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.04 --kv-quant-thresh 3.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.06 --kv-quant-thresh 3.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.08 --kv-quant-thresh 3.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
python3 eval_qa_correct.py --dataset minerva_math --sample-rate 20 --label train --model qwq --model-gen 2 --model-size 32  --log-path ../logs/calibrate_per_token_thresh/qwq-32b --kbits-high 8 --vbits-high 4 --kbits-low 4 --vbits-low 2 --kv-prune-thresh 0.1 --kv-quant-thresh 3.0 --kv-buffer 64 --target-mem-util 0.1 --rounds 1
